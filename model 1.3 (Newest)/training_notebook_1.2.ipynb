{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SibiShanmuga/Tumor-Detection-Algorithm/blob/main/brain_tumor_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gveoam4NyV6o"
      },
      "outputs": [],
      "source": [
        "# --- Setup and Imports ---\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nIvtfT6y5ar",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip -q install kaggle\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "kaggle_json = userdata.get('KAGGLE_JSON')\n",
        "if kaggle_json is None:\n",
        "    files.upload()\n",
        "\n",
        "# Write kaggle.json securely\n",
        "kaggle_dir = os.path.expanduser(\"~/.kaggle\")\n",
        "os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(kaggle_dir, \"kaggle.json\"), \"w\") as f:\n",
        "    f.write(kaggle_json)\n",
        "\n",
        "# Lock down permissions\n",
        "os.chmod(os.path.join(kaggle_dir, \"kaggle.json\"), 0o600)\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "print(\"kaggle.json installed.\")\n",
        "\n",
        "# Download + unzip dataset\n",
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset\n",
        "!unzip -o brain-tumor-mri-dataset.zip -d data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rho7R2V0ye5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Enhanced data generators with stronger augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=12,\n",
        "    width_shift_range=0.10,\n",
        "    height_shift_range=0.10,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,         # medical images shouldn't flip vertically\n",
        "    shear_range=0.00,\n",
        "    brightness_range=(0.85, 1.15),\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2         # 20% for validation\n",
        ")\n",
        "\n",
        "#validation data generator without any augmentation\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        "    )\n",
        "\n",
        "train_dir = '/content/data/Training'\n",
        "\n",
        "#the training split\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "#the validation split\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "#the testing datesets\n",
        "\n",
        "test_dir = '/content/data/Testing'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6uL8Oa21PEk",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# --- Visualize sample images correctly ---\n",
        "images, labels = next(train_gen)  # Get one batch of images and labels\n",
        "\n",
        "# Get class names from the generator\n",
        "class_names = list(train_gen.class_indices.keys())\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    # Get the class index from the one-hot encoded label\n",
        "    class_idx = np.argmax(labels[i])\n",
        "    plt.title(class_names[class_idx]) # Display the actual class name\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orlA6hWv2_aH"
      },
      "source": [
        "Training the dataset with the loaded data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e450ontn2-7Z",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# --- Optimized CNN Model Definition with Batch Normalization ---\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = models.Sequential([\n",
        "    # Block 1\n",
        "    layers.Conv2D(32, (3, 3), strides = (1,1), activation='relu', kernel_regularizer=l2(0.0001), input_shape=(128, 128, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), strides = (1,1), activation='relu', kernel_regularizer=l2(0.0001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # Block 2\n",
        "    layers.Conv2D(64, (3, 3),strides = (1,1), activation='relu', kernel_regularizer=l2(0.0005)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3),strides = (1,1), activation='relu', kernel_regularizer=l2(0.0005)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    # Block 3\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Dropout(0.35),\n",
        "\n",
        "    # Block 4 - Additional depth\n",
        "    layers.Conv2D(192, (3, 3), activation='relu', kernel_regularizer=l2(0.0015)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    # Head Layers\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yczIY19E3c8x"
      },
      "outputs": [],
      "source": [
        "from PIL.Image import init\n",
        "# --- Model Training with Advanced Callbacks ---\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Adjusted class_weight for 4 classes\n",
        "class_weight = {0: 1.0, 1: 1.67, 2: 1.0, 3: 1.1}  # adjust if you detect imbalance\n",
        "\n",
        "# Callbacks for improved training\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=7,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.6,\n",
        "        patience=3,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        \"best_brain_tumor_model.keras\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "TOTAL_EPOCHS = 100\n",
        "history_list = []\n",
        "\n",
        "# Compile with optimized settings\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.04),\n",
        "    metrics=['accuracy'],\n",
        "    run_eagerly=False\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=TOTAL_EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        "    class_weight=class_weight\n",
        ")\n",
        "history_list.append(history)\n",
        "\n",
        "#If the model stopped early we restart training with reset optimizers\n",
        "current_epoch = len(history.history['accuracy'])\n",
        "restarts=1\n",
        "\n",
        "while current_epoch < TOTAL_EPOCHS:\n",
        "\n",
        "  print(\"Restarting Model\\n\")\n",
        "  print(f\"Starting at Epoch: {current_epoch}\\n\")\n",
        "\n",
        "  restarted_model = load_model('best_brain_tumor_model.keras')\n",
        "\n",
        "  restarted_model.compile(\n",
        "    #optimizer now restarts with 0.9% of the initial learning rate, decreasing each restart\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=(0.0004)* (0.9**restarts)),\n",
        "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.01),\n",
        "    metrics=['accuracy'],\n",
        "    run_eagerly=False\n",
        "  )\n",
        "\n",
        "  train_gen.reset()\n",
        "  history = restarted_model.fit(\n",
        "      train_gen,\n",
        "      validation_data=val_gen,\n",
        "      epochs= TOTAL_EPOCHS,\n",
        "      initial_epoch=current_epoch,\n",
        "      callbacks=callbacks,\n",
        "      verbose=1,\n",
        "      class_weight=class_weight\n",
        "  )\n",
        "\n",
        "  history_list.append(history)\n",
        "  current_epoch += len(history.history['accuracy'])\n",
        "  restarts+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZRbP_ot3xPL",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# --- Plot Training Results with Detailed Analysis ---\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Accuracy Plot\n",
        "epoch_offset=0\n",
        "accuracy_first=True\n",
        "plt.subplot(1, 2, 1)\n",
        "for history in history_list:\n",
        "  epochs = range(\n",
        "        epoch_offset,\n",
        "        epoch_offset + len(history.history['accuracy'])\n",
        "  )\n",
        "  plt.plot(epochs, history.history['accuracy'], color='darkslategrey', label= 'Training Accuracy' if accuracy_first else None, linewidth=2)\n",
        "  plt.plot(epochs, history.history['val_accuracy'], color='orangered', label= 'Validation Accuracy' if accuracy_first else None, linewidth=2)\n",
        "  epoch_offset += len(history.history['accuracy'])\n",
        "  plt.axvline(x=epoch_offset, linestyle=':', label= 'restarted model' if accuracy_first else None, linewidth=2)\n",
        "  accuracy_first=False\n",
        "\n",
        "plt.title('Model Accuracy', fontsize=14)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "\n",
        "\n",
        "# Loss Plot\n",
        "epoch_offset=0\n",
        "loss_first=True\n",
        "plt.subplot(1, 2, 2)\n",
        "for history in history_list:\n",
        "  epochs = range(\n",
        "        epoch_offset,\n",
        "        epoch_offset + len(history.history['accuracy'])\n",
        "  )\n",
        "  plt.plot(epochs,history.history['loss'], color='firebrick', label= 'Training Loss' if loss_first else None, linewidth=2)\n",
        "  plt.plot(epochs,history.history['val_loss'], color='darkcyan', label= 'Validation Loss' if loss_first else None, linewidth=2)\n",
        "  epoch_offset += len(history.history['accuracy'])\n",
        "  plt.axvline(x=epoch_offset, linestyle=':', label= 'restarted model' if loss_first else None, linewidth=2)\n",
        "  loss_first=False\n",
        "\n",
        "plt.title('Model Loss', fontsize=14)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.text(-25, -0.05, \"Statistics:\", fontsize=15)\n",
        "plt.text(-25,-0.10,f\"Best Training Accuracy: {max(max(h.history[\"accuracy\"]) for h in history_list):.4f}\")\n",
        "plt.text(-25,-0.15,f\"Best Validation Accuracy: {max(max(h.history[\"val_accuracy\"]) for h in history_list):.4f}\")\n",
        "plt.text(-25,-0.20,f\"Best Training Loss: {min(min(h.history[\"loss\"]) for h in history_list):.4f}\")\n",
        "plt.text(-25,-0.25,f\"Best Validation Loss: {min(min(h.history[\"val_loss\"]) for h in history_list):.4f}\")\n",
        "plt.show()\n",
        "\n",
        "# Print summary\n",
        "print(f\"\\nTraining Summary:\")\n",
        "print(f\"Final Train Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "print(f\"Final Train Loss: {history.history['loss'][-1]:.4f}\")\n",
        "print(f\"Final Validation Loss: {history.history['val_loss'][-1]:.4f}\")\n",
        "print(\"\\n\")\n",
        "print(f\"Best Train Accuracy: {max(max(h.history[\"accuracy\"]) for h in history_list):.4f}\")\n",
        "print(f\"Best Validation Accuracy: {max(max(h.history[\"val_accuracy\"]) for h in history_list):.4f}\")\n",
        "print(f\"Best Train Loss: {min(min(h.history[\"loss\"]) for h in history_list):.4f}\")\n",
        "print(f\"Best Validation Loss: {min(min(h.history[\"val_loss\"]) for h in history_list):.4f}\")\n",
        "print(\"\\n\")\n",
        "print(f\"Total Epochs Trained: {sum(len(h.history[\"accuracy\"]) for h in history_list)}\")\n",
        "print(f\"Total Restarts: {len(history_list)}\")\n",
        "\n",
        "print(\"\\n\");\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "matrix_model=load_model('best_brain_tumor_model.keras')\n",
        "val_gen.reset()\n",
        "probs = matrix_model.predict(val_gen)\n",
        "y_true = val_gen.classes\n",
        "\n",
        "# If categorical (one-hot output)\n",
        "if probs.shape[1] > 1:\n",
        "    y_pred = np.argmax(probs, axis=1)\n",
        "else:\n",
        "    y_pred = (probs.ravel() >= 0.5).astype(int)\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuDKtl8q3zny",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# --- Save Models and Evaluation ---\n",
        "# Save the final trained model\n",
        "model.save('brain_tumor_cnn_model_final.keras')\n",
        "print(\"Final model saved as 'brain_tumor_cnn_model_final.keras'\")\n",
        "\n",
        "# The best model is already saved by ModelCheckpoint callback\n",
        "print(\"Best model saved as 'best_brain_tumor_model.keras' (highest validation accuracy)\")\n",
        "\n",
        "# Load and evaluate the best model\n",
        "from tensorflow.keras.models import load_model\n",
        "best_model = load_model('best_brain_tumor_model.keras')\n",
        "\n",
        "print(\"\\n--- Best Model Performance ---\")\n",
        "eval_results = best_model.evaluate(test_gen)\n",
        "print(f\"Testing Accuracy: {eval_results[1]:.4f}\")\n",
        "print(f\"Testing Loss: {eval_results[0]:.4f}\")\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "test_gen.reset()\n",
        "probs = best_model.predict(test_gen)\n",
        "y_true = test_gen.classes\n",
        "\n",
        "# If categorical (one-hot output)\n",
        "if probs.shape[1] > 1:\n",
        "    y_pred = np.argmax(probs, axis=1)\n",
        "else:\n",
        "    y_pred = (probs.ravel() >= 0.5).astype(int)\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred, digits=4))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}